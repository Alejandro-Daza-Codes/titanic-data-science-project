# titanic-data-science-project
Clasificaci贸n de supervivencia en el Titanic. Proyecto de ML con preprocesamiento (imputaci贸n, One-Hot) y comparaci贸n de 5 modelos (DT, RF, NB, SVM, MLP). El an谩lisis confirm贸 a 'Sexo' y 'Clase' como predictores clave. Random Forest es el mejor modelo, logrando un 83.43% de exactitud en la predicci贸n.
#  Titanic Survival Prediction: Comparaci贸n de Modelos de Clasificaci贸n

##  Descripci贸n del Proyecto

Este repositorio contiene un proyecto de **Machine Learning** enfocado en predecir la supervivencia de los pasajeros del RMS Titanic utilizando el dataset cl谩sico de Kaggle.

El objetivo principal fue **comparar el rendimiento** de cinco algoritmos de clasificaci贸n, aplicando un riguroso proceso de **An谩lisis Exploratorio de Datos (EDA)** y **Preprocesamiento** para optimizar la capacidad de generalizaci贸n de los modelos.

##  Resultados y Conclusi贸n (Benchmark)

Se entrenaron y evaluaron cinco modelos en diferentes proporciones de *split* (90/10 y 60/40) para identificar el m谩s robusto.

El modelo **Random Forest (RF)** demostr贸 el mejor rendimiento en el *split* 60/40, confirm谩ndose como el algoritmo m谩s efectivo para este problema de clasificaci贸n binaria.

| Algoritmo de Clasificaci贸n | Exactitud (100%) | Exactitud (90/10) | Exactitud (60/40) |
| :--- | :--- | :--- | :--- |
| **Random Forest (RF)** | 0.8830 | 0.7865 | **0.8343** |
| Support Vector Machine (SVM) | 0.8459 | 0.8090 | **0.8343** |
| Naive Bayes (NB) | 0.7885 | 0.8202 | 0.8315 |
| rbol de Decisi贸n (DT) | 0.8785 | 0.7865 | 0.8202 |
| Red Neuronal (MLP) | 0.8628 | 0.7865 | 0.8006 |

### Conclusiones Clave del Modelo Ganador (Random Forest)

El an谩lisis de la **Matriz de Confusi贸n** del modelo RF (60/40) mostr贸:
* **Falsos Negativos (FN) Optimizados:** Se minimiz贸 el error m谩s costoso (predecir la muerte de un pasajero que realmente sobrevivi贸), un factor crucial para m茅tricas como el *Recall* y el *F1-Score*.
* **Predictores Dominantes:** El EDA y el an谩lisis de la importancia de caracter铆sticas (Feature Importance) del RF confirmaron que el **G茅nero** (`Sex_male`) y la **Clase del Billete** (`Pclass` / `Fare`) son los factores m谩s influyentes en la supervivencia.

## 锔 Metodolog铆a y Ejecuci贸n

### Archivos
* **`CASO TITANIC.ipynb`**: Cuaderno principal de Colab con todo el proceso (EDA, Preprocesamiento, Entrenamiento y Visualizaciones).
* **`train.csv`**: El dataset original utilizado para el entrenamiento y la evaluaci贸n.

### Pasos Clave del Preprocesamiento

1.  **Gesti贸n de Valores Faltantes (NaNs):**
    * `Age`: Imputada con la media (29.70).
    * `Cabin`: Eliminada debido a la alta tasa de datos faltantes (m谩s del 77%).
    * `Embarked`: Filas eliminadas (solo 2 NaNs).
2.  **Eliminaci贸n de Variables:** Se descartaron `Name`, `PassengerId` y `Ticket` por su nulo valor predictivo.
3.  **Codificaci贸n:** Las variables categ贸ricas (`Sex` y `Embarked`) se transformaron usando **One-Hot Encoding** (`pd.get_dummies`).
4.  **Estandarizaci贸n:** Se aplic贸 **StandardScaler** a las variables num茅ricas para normalizar los datos, paso esencial para SVM y Redes Neuronales.

### Visualizaciones de Modelos
Se incluyeron visualizaciones avanzadas para interpretar los modelos:
* **rbol de Decisi贸n:** Gr谩fico del 谩rbol para ver las reglas expl铆citas (confirmando a `Sex_male` y `Pclass` como nodos principales).
* **Random Forest:** Gr谩fico de importancia de caracter铆sticas (*Feature Importance*).
* **Naive Bayes:** Gr谩fico de distribuci贸n Gaussiana, mostrando la superposici贸n de densidades de probabilidad.
* **Linear SVM (Proxy):** Gr谩fico de coeficientes, que act煤a como un mapa de pesos para las caracter铆sticas.

---
